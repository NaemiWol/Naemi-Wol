---
title: "Hausaufgabe 4"
output: html_notebook
---

```{r}
library(tidyverse)
library(e1071)
library(caret)
library(pROC)
```
```{r}
titanic <- read_delim("titanic.csv", ";", 
    escape_double = FALSE, trim_ws = TRUE)
```


#HAUSAUFGABE 4
#Bitte erstellen Sie ein Notebook mit weiteren Features (Alter, Geschlecht und Klasse sind als Beispiel in meinem Notebook auf GitHub)


```{r}
titanic %>%
  group_by(survived) %>%
  summarize(n = n())
```

#Notebook: Survived, pclass, sibsp, embarked:

```{r}
(titanic.df <-titanic %>%
  select(survived,pclass,sibsp,embarked))
```
```{r}
titanic.df <- na.omit(titanic.df)
titanic.df <- titanic.df %>%
  mutate(survived = as.factor(survived))
```




#Alle NA's rausnehmen:

```{r}
titanic.df <- na.omit(titanic.df)
```

#Character in number ändern:

```{r}
titanic.df%>%
  group_by(embarked)%>%
  summarise(n = n())
```

```{r}
library(DataCombine)
```

#Ersätzen in Numeric

```{r}
Replaces <- data.frame(from = c("C", "Q","S"), to = c("0", "1", "2"))
```

```{r}
titanic.df <- as.data.frame(titanic.df)
```


```{r}
titanic.new <- FindReplace(data = titanic.df, Var = "embarked", replaceData = Replaces,
                     from = "from", to = "to", exact = FALSE)
```

```{r}
titanic.new.vector <- FindReplace(data = titanic.df, Var = "embarked", replaceData = Replaces,
                     from = "from", to = "to", vector = TRUE)
```

#Neuer DataFrame:

```{r}
(titanic.new <- titanic.new%>%
  mutate(survived = as.factor(survived)))
```

#Einteilung in Training und Testing mit der Zufallszahl 100:

```{r}
set.seed(100)
inTrain <- createDataPartition(
  y = titanic.df$survived,
  p = .8,
  list = FALSE)
training <- titanic.df[ inTrain,]
testing  <- titanic.df[-inTrain,]
```
#Training = 320 ; Testing = 78

```{r}
model.svm <- svm(formula = survived ~ ., data = training, probability=TRUE)
summary(model.svm)
pred <- predict(model.svm, testing[,-1], probability = TRUE)
```


```{r}
(test.results <- cbind(pred, testing))
```
```{r}
head(attr(pred, "probabilities"))
```

```{r}
confusionMatrix(pred,testing$survived)
```

```{r}
library(pROC)
pROC_obj <- roc(as.numeric(test.results$survived), as.numeric(test.results$pred),
            smoothed = TRUE,
            ci=TRUE, ci.alpha=0.9, stratified=FALSE,
            plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
            print.auc=TRUE, show.thres=TRUE)
```


#Naive Bayes ALgo

```{r}
my_training <- training %>%
  mutate(survived = as.factor(survived))%>%
  mutate(sibsp = as.factor(sibsp))%>%
  mutate(pclass = as.factor(pclass)) %>%
  mutate(embarked = as.factor(embarked))
model <- naiveBayes(survived ~ ., data = my_training)
model
```

```{r}
my_testing <- testing %>%
  mutate(sibsp = as.factor(sibsp))%>%
  mutate(pclass = as.factor(pclass)) %>%
  mutate(embarked = as.factor(embarked))
pred <- predict(model, my_testing)
table(pred, my_testing$survived)
```


```{r}
(test.results <- cbind(pred, my_testing))
```

```{r}
test.results <- test.results %>%
  mutate(pred = as.numeric(pred))
pROC_obj <- roc(as.numeric(as.character(test.results$survived)), test.results$pred,
            smoothed = TRUE,
            ci=TRUE, ci.alpha=0.9, stratified=FALSE,
            plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
            print.auc=TRUE, show.thres=TRUE)
```

#Decision Tree Algo

```{r}
library(rpart)
library(rpart.plot)
tree<- rpart(survived~., data = training, method = 'class')
rpart.plot(tree)
```




```{r}
test.results2 <- test.results %>%
  mutate(pred = ifelse(pred>=0.5,1,0))
table(test.results2$pred, testing$survived)
```
```{r}
pROC_obj <- roc(model.results.dt$survived,model.results.dt$`1`,
            smoothed = TRUE,
            # arguments for ci
            ci=TRUE, ci.alpha=0.9, stratified=FALSE,
            # arguments for plot
            plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
            print.auc=TRUE, show.thres=TRUE)
```

#Beobachtung: 

- Die Curves Lines der 3 Algo sind unterschiedlich, aber alle 3 betragen die Werte ungefähr 0,6 bis 0,7, was nicht so ideal wäre. AUC sind > 0,5 (SVM: 0,681; Naive Bayer: 0,626 und De)
- SVM hat die beste Perfomance, trotzdem müssen wir beim dem Overfitting vorsichtig sein.
- Die AUC sind minimal (0,040 Differenz) unterschiedlich

#Erklärung:

- SVM arbeitet mit Distanzen, während Naive Bayer mit Kategorie von Datensätzen der Data Frame arbeitet. Das führt zu einem Unterschied in der Performance.



